{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the necessary packages\n",
    "from skimage.segmentation import slic, quickshift\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Extract superpixels and create node features\n",
    "import scipy.ndimage\n",
    "from skimage.segmentation import slic\n",
    "from scipy.spatial.distance import cdist\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 is passed\n",
      "100 is passed\n",
      "150 is passed\n",
      "200 is passed\n",
      "250 is passed\n",
      "300 is passed\n",
      "350 is passed\n",
      "400 is passed\n",
      "450 is passed\n",
      "500 is passed\n",
      "550 is passed\n",
      "600 is passed\n",
      "650 is passed\n",
      "700 is passed\n",
      "750 is passed\n",
      "800 is passed\n",
      "850 is passed\n",
      "900 is passed\n",
      "950 is passed\n",
      "1000 is passed\n",
      "1050 is passed\n",
      "1100 is passed\n",
      "1150 is passed\n",
      "1200 is passed\n",
      "1250 is passed\n",
      "1300 is passed\n",
      "1350 is passed\n",
      "1400 is passed\n",
      "1450 is passed\n",
      "1500 is passed\n",
      "1550 is passed\n"
     ]
    }
   ],
   "source": [
    "##All of this is for train data\n",
    "\n",
    "import os # for iterating over images in a folder\n",
    "# directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_SmallerDataset_refined/Train/Type1'#the/directory/you/want/to/use'\n",
    "# directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Train/Type_1'#the/directory/you/want/to/use'\n",
    "directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Train_final/Type_3'\n",
    "# directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Train/Type_3'\n",
    "# out_path = '/Users/neginashouri/Desktop/Thesis/implimentation/create_superpixels/output'\n",
    "\n",
    "\n",
    "x = 0 \n",
    "image_list=[]\n",
    "all_cp_sp_data = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "        x+=1\n",
    "        \n",
    "        if filename == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        # me: create the full input path and read the file\n",
    "        input_path = os.path.join(directory, filename)\n",
    "        \n",
    "        #me: reading the images\n",
    "        image = Image.open(input_path)\n",
    "        \n",
    "        #me: resizing the images into 1000*1000\n",
    "        image = image.resize((1000, 1000))\n",
    "        \n",
    "        # me: convert the PIL image to numpy\n",
    "        pix = np.array(image.getdata()).reshape(image.size[0], image.size[1],3) # convert the PIL image to numpy instead of # images = (image.numpy() / 255.)\n",
    "#       print(pix.shape)\n",
    "        \n",
    "        pix_np = pix\n",
    "#         print(pix_np.shape)\n",
    " \n",
    "        image_list.append(image)\n",
    "    \n",
    "\n",
    "        img = pix_np.astype(np.double)  # 28x28 MNIST image #in My case 1000 * 1000\n",
    "#         print(\"img shape\",img.shape)\n",
    "\n",
    "        # The number (n_segments) of superpixels returned by SLIC is usually smaller than requested, so we request more\n",
    "        superpixels = slic(image, n_segments=100, compactness=15, multichannel= True, max_iter = 15,sigma = 10)\n",
    "        sp_indices = np.unique(superpixels) # me: che adad hai darim bade superpixel kardan\n",
    "        # print(sp_indices)\n",
    "        n_sp = len(sp_indices)  # should be 74 with these parameters of slic #me: yani chanta daste bandi bara supper pixel\n",
    "#         print(n_sp)\n",
    "\n",
    "\n",
    "        sp_intensity = np.zeros((n_sp, 3), np.float32) # me: I added the 3rd dim (3)? is it correct?\n",
    "        # print(sp_intensity)\n",
    "        sp_coord = np.zeros((n_sp, 2), np.float32)  # row, col  # me: I added the 3rd dim (3)?is it correct?\n",
    "        # print(sp_coord)\n",
    "\n",
    "\n",
    "        for seg in sp_indices:\n",
    "            mask = superpixels == seg # me: mask = True/False , \n",
    "#             print(mask.shape)\n",
    "\n",
    "\n",
    "        ### intensity is the mean of each sp area and coord is the center of them. As they are the same on each layer(R,G,B), we are just calculating them on one layer. thay is why we used mask [:,:,1]\n",
    "#             sp_intensity[seg] = np.concatenate([np.mean(img[mask]),np.mean(img[mask]),np.mean(img[mask])])\n",
    "#             sp_intensity[seg] = np.mean(img[mask])\n",
    "        ### /255 because the numbers in bench mark are 0< <1\n",
    "            img1 = img[:,:,0]/255.0\n",
    "#             print(\"shape img1\",img1.shape)\n",
    "            img1_ex = np.expand_dims(np.mean(img1[mask]), axis=0)\n",
    "#             print(\"layer1 mean one seg:\",img1_ex)\n",
    "            \n",
    "            img2 = img[:,:,1]/255.0\n",
    "            img2_ex = np.expand_dims(np.mean(img2[mask]), axis=0)\n",
    "#             print(\"layer2 mean one seg:\",img2_ex)\n",
    "\n",
    "            img3 = img[:,:,2]/255.0\n",
    "            img3_ex = np.expand_dims(np.mean(img3[mask]), axis=0)\n",
    "#             print(\"layer2 mean one seg:\",img3_ex)\n",
    "            \n",
    "#             print(\"sp_intensity shape one seg:\",np.concatenate([img1_ex,img2_ex,img3_ex]))\n",
    "                  \n",
    "            sp_intensity[seg] = np.concatenate([img1_ex,img2_ex,img3_ex])\n",
    "#             print(sp_intensity.shape)\n",
    "            sp_coord[seg] = np.array(scipy.ndimage.measurements.center_of_mass(mask)) #me: checked and all the layers have the same center # me:I think it is finding the location of the center of the mass#me : So the sp_coord is our nodes now\n",
    "#             print(sp_coord.shape)\n",
    "#             print(\"first layer sp\",np.array(scipy.ndimage.measurements.center_of_mass(mask[:,:,0])))\n",
    "#             print(\"2nd layer sp\",np.array(scipy.ndimage.measurements.center_of_mass(mask[:,:,1])))\n",
    "#             print(\"3rd layer sp\",np.array(scipy.ndimage.measurements.center_of_mass(mask[:,:,2])))\n",
    "#             if(np.random.rand() < 0.5):\n",
    "#                 sp_intensity[seg] = math.nan\n",
    "#                 sp_coord[seg] = (math.nan,math.nan)\n",
    "#                 print(\"gharare berini\")\n",
    "#             if np.isnan(sp_intensity[seg]):\n",
    "#                 print(\"begoo RIDI\")\n",
    "#             if np.isnan(sp_coord[seg][0]):\n",
    "#                 print(\"begoo RIDI 2bare\")\n",
    "            \n",
    "#         print(\"this is intensity\",sp_intensity)\n",
    "#         print(\"this is coord\",sp_coord)\n",
    "        cp_sp_data = (sp_intensity,sp_coord,sp_indices) ## this gives us the same format we want but shape is not ok and not sure if the whole list will be the same as what we want\n",
    "#         print(cp_sp_data)\n",
    "#         print(len(cp_sp_data))\n",
    "        all_cp_sp_data.append(cp_sp_data) ## stack all the CPs\n",
    "#         print(len(all_cp_sp_data))\n",
    "        \n",
    "            \n",
    "        if(x%50 == 0):\n",
    "            print(f'{x} is passed')\n",
    "            \n",
    "#         if (x==5):\n",
    "        \n",
    "    \n",
    "##Me: in type{}_in_co_sp.data we are saving sp_intensity, sp_coord, sp_indices in 1 list, needs to be reshape to be aligned with other types sp shapes\n",
    "        with open('type3_in_co_sp.pkl', 'wb') as filehandle:\n",
    "            # store the data as binary data stream\n",
    "            pickle.dump(all_cp_sp_data, filehandle)\n",
    "\n",
    "\n",
    "#             break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 is passed\n",
      "100 is passed\n",
      "150 is passed\n"
     ]
    }
   ],
   "source": [
    "##All of this is for test data\n",
    "\n",
    "import os # for iterating over images in a folder\n",
    "# directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Test/Type_1'\n",
    "# directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Test/Type_2'\n",
    "directory = '/Users/neginashouri/Desktop/Thesis/implimentation/CP_Dataset_refined/Test/Type_3'\n",
    "\n",
    "\n",
    "x = 0 \n",
    "image_list=[]\n",
    "all_cp_sp_data = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "        x+=1\n",
    "\n",
    "        if filename == '.DS_Store':\n",
    "            continue\n",
    "        # me: create the full input path and read the file\n",
    "        input_path = os.path.join(directory, filename)\n",
    "        \n",
    "        \n",
    "        #me: reading the images\n",
    "        image = Image.open(input_path)\n",
    "        \n",
    "        #me: resizing the images into 1000*1000\n",
    "        image = image.resize((1000, 1000))\n",
    "        \n",
    "        # me: convert the PIL image to numpy\n",
    "        pix = np.array(image.getdata()).reshape(image.size[0], image.size[1],3) # convert the PIL image to numpy instead of # images = (image.numpy() / 255.)\n",
    "#       print(pix.shape)\n",
    "        \n",
    "        pix_np = pix\n",
    "#         print(pix_np.shape)\n",
    " \n",
    "        image_list.append(image)\n",
    "    \n",
    "\n",
    "        img = pix_np.astype(np.double)  # 28x28 MNIST image #in My case 1000 * 1000\n",
    "#         print(\"img shape\",img.shape)\n",
    "\n",
    "        # The number (n_segments) of superpixels returned by SLIC is usually smaller than requested, so we request more\n",
    "        superpixels = slic(image, n_segments=100, compactness=15, multichannel= True, max_iter = 15,sigma = 10)\n",
    "        sp_indices = np.unique(superpixels) # me: che adad hai darim bade superpixel kardan\n",
    "        # print(sp_indices)\n",
    "        n_sp = len(sp_indices)  # should be 74 with these parameters of slic #me: yani chanta daste bandi bara supper pixel\n",
    "#         print(n_sp)\n",
    "\n",
    "\n",
    "        sp_intensity = np.zeros((n_sp, 3), np.float32) # me: I added the 3rd dim (3)? is it correct?\n",
    "        # print(sp_intensity)\n",
    "        sp_coord = np.zeros((n_sp, 2), np.float32)  # row, col  # me: I added the 3rd dim (3)?is it correct?\n",
    "        # print(sp_coord)\n",
    "\n",
    "\n",
    "        for seg in sp_indices:\n",
    "            mask = superpixels == seg # me: mask = True/False , \n",
    "#             print(mask.shape)\n",
    "\n",
    "\n",
    "        ### /255 because the numbers in bench mark are 0< <1\n",
    "            img1 = img[:,:,0]/255.0\n",
    "#             print(\"shape img1\",img1.shape)\n",
    "            img1_ex = np.expand_dims(np.mean(img1[mask]), axis=0)\n",
    "#             print(\"layer1 mean one seg:\",img1_ex)\n",
    "            \n",
    "            img2 = img[:,:,1]/255.0\n",
    "            img2_ex = np.expand_dims(np.mean(img2[mask]), axis=0)\n",
    "#             print(\"layer2 mean one seg:\",img2_ex)\n",
    "\n",
    "            img3 = img[:,:,2]/255.0\n",
    "            img3_ex = np.expand_dims(np.mean(img3[mask]), axis=0)\n",
    "#             print(\"layer2 mean one seg:\",img3_ex)\n",
    "            \n",
    "#             print(\"sp_intensity shape one seg:\",np.concatenate([img1_ex,img2_ex,img3_ex]))\n",
    "                  \n",
    "            sp_intensity[seg] = np.concatenate([img1_ex,img2_ex,img3_ex])\n",
    "#             print(sp_intensity.shape)\n",
    "            sp_coord[seg] = np.array(scipy.ndimage.measurements.center_of_mass(mask)) #me: checked and all the layers have the same center # me:I think it is finding the location of the center of the mass#me : So the sp_coord is our nodes now\n",
    "\n",
    "            \n",
    "\n",
    "        cp_sp_data = (sp_intensity,sp_coord,sp_indices) ## this gives us the same format we want but shape is not ok and not sure if the whole list will be the same as what we want\n",
    "#         print(cp_sp_data)\n",
    "#         print(len(cp_sp_data))\n",
    "        all_cp_sp_data.append(cp_sp_data) ## stack all the CPs\n",
    "#         print(len(all_cp_sp_data))\n",
    "        \n",
    "            \n",
    "        if(x%50 == 0):\n",
    "            print(f'{x} is passed')\n",
    "            \n",
    "#         if (x==5):\n",
    "        \n",
    "    \n",
    "##Me: in type{}_in_co_sp.data we are saving sp_intensity, sp_coord, sp_indices in 1 list, needs to be reshape to be aligned with other types sp shapes\n",
    "        \n",
    "#         for typ in range(1,4):\n",
    "        with open('test_type3_in_co_sp.pkl', 'wb') as filehandle:\n",
    "            # store the data as binary data stream\n",
    "            pickle.dump(all_cp_sp_data, filehandle)\n",
    "\n",
    "\n",
    "#             break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
